{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25c8557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://sunstonepartners.com/', 'https://www.appliedlearning.com/', 'https://www.forsalebyowner.com/', 'http://comsatmedia-en.tumblr.com/', 'https://www.kdanmobile.com/', 'https://www.sunchlorellausa.com/', 'https://www.papemh.com/', 'https://everstream.net/', 'https://wackerbrewing.com/', 'https://21stsoft.com/', 'https://marketingbysos.com/', 'https://www.wittmann-group.com/en', 'https://www.xelapack.com/', 'https://epicio.com/', 'https://mammachia.com/', 'https://cambli.com/', '', 'https://www.river-run.com/', 'https://www.re-soft.com/', 'https://www.pavestone.com/', 'https://www.framedisplays.com/', 'https://www.virtually-anywhere.com/', 'https://abak.hopem.com/', 'https://jswsteel.us/', 'https://www.glr.qc.ca/', 'http://www.woodrock.com/', 'https://tracegenomics.com/', 'https://avada.com/', '', 'https://www.cthedge.org/', 'https://greenecowalls.com/', 'https://www.ripoffreportremovalhelp.com/', 'https://www.kumi-na.com/', 'https://libertynet.com', 'https://www.ptechnosoft.com/', 'https://agmimports.com/', 'https://longevity.inc/', 'https://www.ramboard.com/', 'https://www.macuhealth.com/', '', 'https://cloudsilicon.com/', 'https://www.unitedpacificpallet.com/', 'https://breakthroughenergy.org/', 'https://www.traceinternational.org/', 'https://www.renocavanaugh.com/', 'https://blankfactor.com/', 'https://www.pinta-elements.com/', 'https://www.covalentmediasystems.com/', 'https://mittera.com/higher-education/', 'https://transcendinfra.com/', 'https://edgewood.org/', 'https://traivefinance.com/', 'https://www.bizx.com/', 'https://ecmins.com/', 'https://www.enveloprisk.com/', 'http://sensormedtech.com/', 'https://www.newgroupmedia.com/home/', 'https://www.nelsonsystems.com/', 'https://www.adsrole.com/', 'https://www.usef.org/errors/not-found?aspxerrorpath=/', 'https://acadia.io/', 'https://www.endosoft.com/', 'https://www.pro-tow.com/', 'https://pexapark.com/', '', 'https://www.web.asignio.com/', 'https://www.printgiant.com/', 'https://www.ease.co/', 'https://www.ussfcu.org/', 'https://www.sporter.com/en-ae/', '', 'https://www.paramountexport.net/', '', '', 'https://www.bladefinancialservices.com/', 'https://www.hwtrek.com/', 'https://www.viewgol.com/', 'https://lamontanita.coop/', 'https://www.pathenviro.com/', 'https://www.affinityventures.com/', '', 'https://verityplatform.com/', 'https://restorepoint.ai/', 'https://www.peachtreegroup.com/', 'https://www.procaretherapy.com/', '', 'https://www.leachgarner.com/', '', 'https://www.altiusva.com/', 'https://coxpools.com/', 'http://invaterra.com/', 'https://www.gnuralnet.com/', 'https://pfnyc.org/', 'http://www.e-acen.com/', 'https://precisionopinion.com/', 'http://www.approgence.com/', 'https://custommicrowave.com/', '', 'https://bonniekatzdesign.com/', 'https://www.dentalrevenue.com/', 'https://www.maxbounty.com/', 'http://www.cnetworktv.com/', 'http://www.a3cube-inc.com/', 'https://www.producthunt.com/', 'https://www.lmvna.org/', 'http://lstjobs.com/', 'https://www.skyword.com/', 'https://www.ziffrenlaw.com/', 'https://www.insightmonk.com/', 'https://activedata.com/', 'https://meawallet.com/', 'https://www.jvox.com.tw/', 'https://www.teamengine.io/', '', 'https://www.montel.com/en', 'http://www.kaiequity.com/', 'https://www.rootermancan.com/', 'http://www.laducer.com/', '', 'https://alkargifts.com/', 'https://us.kef.com/', 'https://www.onlinechiro.com/', 'http://imtechgraphics.com/', 'https://www.c3f.ca/', 'https://arrivehealth.com/', 'https://www.business-class.com/', 'https://www.hys-enterprise.com/', 'https://www.lutechmedical.com/', '', 'http://www.pluravida.com/', 'https://redeam.com/', 'https://thefrankagency.com/', 'https://ecardsystems.com/', 'https://www.kanetix.ca/kanetix-becomes-ratesdotca', '', 'https://nexwebsites.com/', 'https://europeanhome.com/', '', 'https://www.tablift.com/', 'https://deepsee.ai/', '', 'https://custom-metalcraft.com/', 'https://www.softserveinc.com/en-us', 'https://modernvascular.com/', 'https://impactia.com/', 'https://www.abeam.com/', 'http://www.ticss.net/', 'http://ww38.comle.com/', '', 'https://pfscm.org/', 'https://www.forte.io/', 'https://www.produceinventory.com/', 'https://www.keithpiersontoyota.com/', 'https://www.politics-prose.com/', 'https://consulatehc.com/', 'http://www.streamlinesaves.com/', '', 'https://www.voxie.com/', 'https://tpncommerce.com/', 'https://www.plasticsnews.com/', 'https://www.kitchenbrains.com/', 'https://www.peakproperties.biz/', 'https://fogsoft.com/', 'https://outdoorelementstx.com/', '', '', 'https://www.bravofolio.com/', 'http://www.cascadevalley.org/', 'https://arrakistx.com/', 'https://www.evergent.com/', 'https://www.kleinhornig.com/', 'https://www.komgo.io/', 'https://www.texasswfloors.com/', 'http://www.videogenix.com/', 'http://www.gz-audio.com/', 'https://www.ggwp.com/', 'https://www.i-techsupport.com/', 'https://www.experiencewelcome.com/', '', 'https://graffiticaps.com/', 'https://thinkbooker.com/', '', 'https://atpcoalition.com/', 'http://www.bowful.com/', 'https://workera.ai/', 'https://kx.com/', 'https://argyle.com/', 'https://spherecommerce.com/', 'https://www.blnautism.com/', 'https://optiwatt.com/', 'https://go2.org/', 'https://yepads.com/', 'https://www.flashine.com/', 'https://www.dashly.io/', 'https://www.isphere.net/', '', 'https://canary.is/', 'https://www.burkeoil.com/', 'https://www.shortcuts.com.au/', 'https://www.winanalytics.com/', 'https://www.finsightvc.com/', 'https://doubleblackimaging.com/', 'http://www.swengcon.com/', 'https://www.intellisystems.com/', 'https://piepacker.com/', 'http://www.assetsmart.com/', 'http://www.trydti.com/index.html', 'https://usiafrica.com/', '', 'https://digitaldelve.com/', 'https://www.catholic.ac.kr/', 'https://www.partnerforces.com/', 'http://kts.packetfusion.com', 'https://hellohero.com/', 'https://www.ultramain.com/', 'https://ribbonfactory.com/', 'https://finally.com/', 'https://www.pasport.com/', 'https://daftcode.pl/', 'https://bodysupport.com/', '', 'https://www.morsecorp.com/', 'https://www.modernanimal.com/', 'https://www.uncharted.software/', 'https://www.gencoat.com/', 'https://vesselhealth.com/', 'https://www.crfonline.org/', 'https://www.acuitymi.com/', 'https://www.dustmaster.com/', 'http://www.giftconnect.co/', 'https://www.dvorakauctionservice.com/', 'https://spinenevada.com/', 'https://www.wildapricot.com/', 'https://www.offitcapital.com/', 'https://complianceservicesgroup.com/', 'https://ipd2.com/', 'https://www.riccino.com.cn/', 'https://www.obesityaction.org/', 'https://www.octanesoftware.net/', 'https://cessco.ca/', 'https://onlyonesource.com/', 'https://www.rhs.org.uk/', 'https://www.springplace.com/', 'https://yukonpartners.com/', 'https://www.snaketray.com/', 'https://www.zoweewow.com/', 'https://velocityrecoveries.com/', 'http://www.iconnect-corp.com/', 'https://www.graphen.ai/', 'https://hallow.com/', 'http://www.kratoscap.com/', 'https://easternshorejobs.com/', 'https://www.openonesolutions.com/', 'https://iquartic.com/', 'https://www.contrastcreative.com/', '', 'https://thefunctionary.com/', 'https://impactpaymentsrecruiting.com/', 'https://www.practicenumbers.com/', 'https://www.dominickanddickerman.com/', 'https://tensentric.com/', '', 'https://www.recastsoftware.com/endpoint-insights/', 'http://ww38.cashedoutmedia.com/', '', 'https://honeytreeelc.com/', 'https://jell-tech.com/', 'https://seattlestudyclub.com/', 'https://andesaservices.com/', 'https://www.porticos.net/', 'https://www.itandsllc.com/', 'https://www.douglasknight.com/', 'https://www.kubisys.com/', 'https://orientcorporation.com/', 'https://www.greynoise.io/', 'https://www.rosettatechnologies.com/', 'https://www.dentallearning.net/', '', 'https://www.owens-minor.com/', 'https://www.aschemanoil.com/', 'https://primeresource.com/', '', 'https://www.proscend.com/', 'https://alliancehcm.com/', 'https://www.ascendstaffing.com/', '', '', 'https://www.midwesternbioag.com/', 'https://www.bornfight.com/', '', 'https://www.opticalworks.com/', 'https://www.lowensign.com/pages/default.aspx', 'https://www.getparallax.com/', 'https://www.i-evolve.com/', 'https://peerrealty.com/', 'https://www.wgnielsen.com/', '', 'https://www.crsoftware.com/', 'https://seoversite.com/', 'https://www.intellipeaksolutions.com/', 'https://medx.com/', 'https://streamyard.com/', 'https://www.ifm.org/', '', 'https://www.mptsweb.net/', 'https://www.kandd.com/', 'https://www.ctd.ai/', 'http://www.uc-point.com/', 'https://www.ezpi.us/', 'https://digitalsky.com/', 'http://worldportsource.com/', 'https://www.cshco.com/', '', 'https://riviana.com/', 'http://www.fitzpatrickmfgco.com/', 'https://www.trademo.com/', 'https://telecoms.com/', 'http://www.fisherlab.com/', 'https://eco-fusion.com/', 'https://www.infinitus.ai/', 'https://otstaffing.com/', 'https://www.impakanalytics.com/', 'https://www.stryker.com/us/en/portfolios/medical-surgical-equipment/surgical-visualization.html', 'https://wingcontrol.com/', 'https://neuro.net/ru/', 'https://www.facilis.com/', 'https://www.noelkerhull.com/', 'https://www.accuphase.com/', 'https://www.mmhmm.app/en/home', 'https://www.dataxstream.com/', 'https://rscapital.com/', 'https://summitig.com/', 'https://tricorauto.com/', 'https://sportening.com/', '', 'https://spcs.stanford.edu/', 'https://www.macauto-group.com/', 'https://aimlabs.com/', 'https://daston.com/', 'https://iconparkingsystems.com/', 'https://uniphyhealth.com/', 'https://www.bellbh.com/', 'https://vofoxsolutions.com/', 'https://www.eir-inc.com/', 'https://www.need.org/', '', 'https://pharosproduction.com/', 'https://www.londonproperties.com/', 'https://www.impact-technology.com/', 'https://www.newbridgesecurities.com/', 'https://rdservices.com/', 'https://revalizesoftware.com/', 'https://www.baldwinhardware.com/', 'https://www.streetplus.net/', 'https://www.vandersteen.com/', 'https://underdefense.com/', 'https://www.united-bk.com/', 'https://estafetausa.com/', 'https://q-reviews.com/', 'https://grandliving.com/', 'https://www.boniangroup.com/', 'https://gatemaninc.biz/', 'https://www.ltcintegrity.com/', 'https://www.bridgedale.com/', '', 'https://www.accessunited.com/', '', 'http://www.morriseyegroup.com/', 'https://brkthru.com/', 'https://www.swnat.com/', 'https://sixfeetup.com/', 'http://ethicareadvisors.com/', 'https://jacoti.com/', 'https://www.masonhub.co/', 'https://nebat.com/', 'https://irhusa.com/', 'https://www.auctionedge.com/', '', 'https://www.anytimemailbox.com/', 'https://www.scrantonproducts.com/', '', 'https://www.barts.eu/', 'https://www.aaed.org/', 'https://ffbt.com/', '', 'https://www.paperwise.com/', '', 'https://www.goodunited.io/', 'https://denovodental.com/', 'http://www.reversemortgageeducators.com/', 'http://www.gandh.co.kr/', 'https://www.devnetwork.com/', 'https://www.gulfstreammarine.com/', 'https://www.irmworldwide.com/', 'https://www.industrialinfo.com/', 'https://www.harlequin.com/shop/index.html', 'https://www.micro1.ai/', 'http://www.foodservicedailynews.com/', 'http://makenote.co/', 'http://www.hosowell.com/', 'https://www.bellefleurtech.com/', 'https://www.georgiasown.org/', 'https://www.ryantrans.com/', '', 'https://availcarsharing.com/', 'https://www.payermatrix.com/', 'http://athenianfoods.com/portal/', '', 'http://www.szforter.com/', 'https://kaliin.com/', 'https://www.boemortgage.com/', '', 'https://idsinc.com/', 'https://bioreigns.com/', 'https://www.altron.com/', 'https://www.theloanprogram.org/', 'http://www.edausa.com/', '', 'https://tscables.com/', 'https://avantilinens.com/', 'https://motionrecruitment.com?o=js', 'https://www.thedoctors.com/', 'https://www.helloscholar.com/', '', 'https://hotsalsainteractive.com/', 'http://www.twgplus.com/', 'https://www.niterider.com/', 'https://www.facet.net/', 'https://clpud.org/', 'https://www.withmehealth.com/', 'https://www.nacsport.com/index.php?lc=en-us', 'https://www.marcalpaper.com/', 'https://www.baytalkitec.com/', 'http://www.thsinternational.com/', 'https://www.oo-software.com/en/', '', '', 'https://conservancy.org/', 'https://xpanse.com/', 'https://www.phmstaffing.com/', 'http://www.osell.com', 'https://innowise-group.com/', 'http://www.imacutech.com/', 'http://www.metascale.com/', '', 'http://www.rinkersystems.com/', 'https://www.mountainmikespizza.com/', 'https://www.getduos.com/', 'https://www.siliconcoach.com/', 'https://www.hillcrestfoods.com/', 'https://www.canarx.com/', 'https://allianceusaonline.com/', 'https://www.aitcomposites.com/', 'https://grisport.it/', 'https://www.gomage.com/', '', 'https://nurseio.com/', 'https://sublimemedia.com/', 'https://www.joincabinet.com/', 'https://www.iterate.ai/', 'https://www.trapezio.com/', 'https://livebdsmcams.net/', '', 'https://korbicom.com/', 'http://ultimosoft.com/', 'https://www.apiject.com/', 'https://www.homesitebusinessinsurance.com/', 'https://www.mawdpathology.com/', '', 'https://www.strombergarchitectural.com/', 'https://www.nationalacademies.org/', 'https://dsebearing.com/', 'https://www.temporal.io/', 'https://www.eaglecopters.com/', 'https://www.sfox.com/', 'https://www.kingfishgroup.com/', 'https://www.hallmarkhomesassociates.com/', 'https://bytzsoft.com/', 'https://www.telecompaper.com/', 'https://www.finovera.com/', 'https://imquant.com/', 'https://www.metabase.com/', 'https://www.dewengineering.com/', 'https://www.avmc.army.mil/', '', 'https://www.kramonandgraham.com/', 'https://www.routethis.com/', 'https://serverscheck.infrasensing.com/', 'http://www.ahtusa.net/', '', 'http://www.rsft.com/', 'https://valoremreply.com/', 'https://solofunds.com/', 'http://www.clinapps.com/', 'https://celltexbank.com/', 'https://pinglestudio.com/', 'http://www.exim.com.tr/', '', 'http://www.kingpakinc.com/', 'https://pearpop.com/', 'https://www.citizenschools.org/', '', 'https://bnctransit.com/', 'https://www.jonescork.com/', 'https://www.dccp.com/', 'https://www.signalsdefense.com/', 'https://www.cenzasmart.com/cenza/food-beverage-training/default.aspx', 'http://www.zyelec.com/', 'https://www.avenulearning.com:443/', 'https://www.4sitestudios.com/', 'https://hawk-igpspunchclock.com/', 'https://www.amtechsoftware.com/', 'https://coopereic.com/', 'https://captcha.com/', 'https://www.apeiron-biologics.com/', '', '', 'https://dan.com/buy-domain/terraindata.com?redirected=true', 'https://green-leaf.us/', 'https://pebco.com/', 'https://www.mavenwave.com/', 'https://altonindustries.com/', '', 'https://www.tapstream.com/', 'https://mavenagency.com/', 'https://www.fawry.com/', 'https://rainbow.me/', 'https://www.joslyn-mfg.com/', 'https://www.liquibase.com/', 'https://www.campusce.com/', 'https://thepacecompanies.com/', 'https://www.sistemi.com/', 'https://www.iasonline.org/', 'http://www.theragenetex.com/en/', '', 'https://fridaycrm.com/', 'https://www.asd-usa.com/', 'https://www.gpsimpact.com/', 'https://www.loadspring.com/', 'http://www.shca.com/', 'https://latitude247.aero/', 'http://www.brandequity.com/', 'https://www.controlgrips.com/', 'https://www.accustarlabs.com/', 'https://hypersizer.com/', 'https://www.vitec.com/', 'https://tri-lift.com/', 'https://coladv.com/', 'https://www.wearecontent.com/', 'https://emphasoft.com/', '', 'https://www.megazebra.com/', 'https://yavli.com/', 'https://patchmypc.com/', 'https://www.chubb.com/ca-en/', 'https://superiortanklines.com/', 'https://www.leerink.com/', 'https://www.springhillcompany.com/', 'https://www.hostmonster.com/', 'https://brasiltelemedicina.com.br/', 'https://www.quakecitycaps.com/', 'https://www.dclainc.com/Membership/Apps/v4DCLA_WF_App.aspx?ReturnURL=/', 'https://hctechguys.com/', 'https://www.grindmaster.com/', 'https://gmcsusa.com/', '', 'https://www.kcm.com/', 'https://www.mascom.bw/', 'https://www.asosmiles.com/', 'https://xwalk.com/', 'https://www.btcc.com/en-US', 'https://www.internationalcybernetics.com/', 'https://www.advancedresources.com/', 'https://mtnview.ca/', 'https://www.rocsoft.com/', 'https://adrny.com/', 'https://ipresidium.com/', 'https://www.cois.org/', 'http://www.ohls.com/', 'https://www.veise.com/', 'https://www.transformativemed.com/', 'https://protransportation.com/', 'https://www.mjrost.com/', 'https://gryphon.ai/', 'https://www.hnas.com/', '', 'https://www.quantamatrix.com/', 'https://www.engineeringplans.com', 'https://www.promptinstitute.com/', 'https://dagster.io/about', 'https://www.securitiesamerica.com/', 'https://www.heluss.com/', 'https://www.key.com/cainbrothers', 'https://gigiaesthetics.com/', 'https://evermos.com/home/', 'https://www.noma.net/', 'https://www.diamondresinproducts.com/', 'http://www.raon-tech.com/', 'https://www.zecops.com/', 'https://www.nedelta.com/', '', 'https://www.plotwatt.com/', 'https://www.kestramedical.com/', 'https://www.peoplehr.com/en-gb/', 'https://spohnc.org/', 'https://www.amlegal.com/', 'https://www.komperdell.com/de', 'https://objectivegroup.com/', 'https://www.folsmedia.com/', 'https://vantek.org/', '', 'https://www.stowers.org/', 'https://www.roamly.com/', 'https://begingroup.com/en/', 'http://www.sonik.com/', 'https://www.grandtrunk.com/', 'https://nira.com/', 'https://www.algoworks.com/', 'https://industrialphysics.com/brands/cmc-kuhnke/', 'https://www.vroozi.com/', 'https://alung.com/', 'https://www.dxsherpa.com/', 'https://bassemiers.com/', 'https://www.breninc.com/', 'https://www.j-display.com/', 'https://www.walnut.io/', 'https://www.qtrade.ca/en/investor.html', '', 'https://optimatics.com/', 'https://phillipssteel.com/', 'https://globalaes.com/', 'https://smart3rdparty.com/', 'https://www.collprofinc.com/', '', 'https://www.mac-tech.net/', 'https://www.socketlabs.com/', 'http://midbanksolutions.com/', 'https://htt.io/', 'https://www.dukaneprecast.com/', 'https://www.workgenius.com/', 'https://itnowinc.com/', '', '', 'https://www.piratescove.net/', 'https://blackpixel.com/', 'http://www.truemotionspine.com/', 'https://www.daysmart.com/', 'https://carolinaturfandmosquito.com/', 'http://kanapsystems.com/', '', 'https://www.treepros.com/', '', 'https://caspian.tech/', 'https://www.nbome.org/', '', 'https://www.iglass.net/', 'https://buggbusters.com/', 'https://bulloch.solutions/home/', '', '', 'http://www.ezfone.com.cn/', 'https://llamazoo.com/', 'https://wentworthgallery.com/', '', 'https://hscwarranty.com/', 'http://www.mollypitcher-oysterpoint.com/', 'https://www.comconsult.com/', 'http://www.vasamed.com/', '', 'https://www.nordic-enterprises.com/', 'https://www.socialnature.com/', 'https://global.wilsonlearning.com/', 'https://www.lexar.com/', 'https://www.landmarkhw.com/', 'https://www.sunprint.com/', 'https://www.thirdera.com/', 'https://aures.com/en/', 'https://www.mississippipower.com/', 'https://www.alpacaimports.com/', 'https://www.matik.io/', 'https://www.precorp.coop/', 'https://www.vincentfister.com/', 'https://www.motaword.com/', 'https://www.phase3mc.com/tmg', 'http://www.prodigyapex.com/', 'https://kfpit.com/', 'https://www.lansing.org/', 'https://www.quantechsoftware.com/', 'https://www.gobuncha.com/', '', 'https://www.comnet.net/', '', 'http://www.ecomsolinc.com/', 'https://www.qt.io/', 'https://www.acceleration.biz/', 'https://www.visitomaha.com/', 'https://www.shopeei.com/', 'https://nbtvinc.com/', 'https://www.washingtoncapitalpartners.com/', 'https://blenny-beagle-kabk.squarespace.com/', 'http://studentloangenius.com/', 'https://highbury-defense.com/', 'https://silverregulatoryassociates.com/', 'https://www.pricetrakker.com/', 'https://visitmontgomery.com/', 'https://www.doosanportablepower.com/na/en', 'https://www.encodia.com/', '', 'https://shorthand.com/', 'https://cloud.google.com/migrate/virtual-machines', 'https://www.interior-tech.com/', 'https://www.riversmoorehead.com/', 'https://amafruits.com/', 'http://labs.lupusalpha.com/', 'https://separfilter.com/', 'https://www.verustat.com/', 'https://hicoamerica.com/', '', 'https://www.intelex.com/predictivesolutions', 'https://www.waterpuretechnologies.com/', 'https://www.finalmilesolar.com/', 'http://www.elcwp.com/', 'https://procureitusa.com/', 'https://www.gibraltarit.com/', 'https://www.firerescue1academy.com/', 'https://intelligentproduct.solutions/', 'https://www.rapidrobotics.com/', 'https://repositrak.com/', 'https://www.idealtransportation.com/', 'https://www.epicentermemphis.org/', 'https://tristarups.com/', 'https://r-f.com/', 'https://www.turbineinletcooling.org/', 'https://webstarted.com/', 'https://thenortheastgroup.com/', '', 'https://www.voxco.com/', '', 'https://cb20.com/', '', '', 'https://nafcofab.com/', 'https://www.issvalue.com/', 'https://www.lean-media.com/', 'https://avoautomation.ai/', 'https://www.fauske.com/', 'https://www.anagocleaning.com/', 'https://www.rialtic.io/', 'http://vpssinc.com/', 'https://www.wellnesscovid.com/', 'https://www.innovaevcarshare.com/', 'https://infare.com/', 'https://www.etymotic.com/', 'https://aem.eco/', 'https://opendrives.com/', 'https://carlsoncapitol.com/', 'https://www.ambitioncs.com/', 'https://houstonwastesolutions.com/', '', 'https://www.mate-usa.com/', 'https://immersed.com/', 'https://www.fhfcu.org/', 'https://illumus.com/', 'https://www.barracudamsp.com/products/xdr/extended-detection-and-response-xdr', 'https://www.netreo.com/', 'https://www.sciplay.com/', 'http://hydrodramatics.com/', '', 'https://www.telesofia.com/', 'https://www.okteto.com/', 'https://protecequip.com/', 'https://www.aptopayments.com/', 'https://www.open-e.com/', 'https://www.mennta.com/', 'https://www.eternussolutions.com/', 'http://www.vidasystems.com/', 'https://www.bosmeadery.com/', 'https://www.mt2.fr/', 'http://ww25.sqltechnologies.us/?subid1=20231002-1740-1153-a2a0-c7ed3e82cacc', 'https://www.emazzanti.net/', 'https://galvanized.com/', 'https://www.econnectglobal.com/', 'https://www.universityradiology.com/', 'https://qontigo.com', 'https://www.connoils.com/', 'http://www.life180inc.com/', 'https://www.azardecorating.com/', 'https://www.meetmax.com/', 'https://fisherassoc.com/', '', 'http://ww16.driveable.com.au/?sub1=20231002-1740-12a8-a9af-7719af27660b', 'https://www.delmontehotels.com/', 'https://www.apgdisplays.com/', 'http://www.ata.net.cn/', 'https://yowieworld.com/', 'https://bnrllc.com/', 'https://www.capturis.com/', '', '', 'https://www.home.driverfacts.com', 'http://www.responseco.com/', 'https://www.zaigoinfotech.com/', 'https://www.accutechortho.com/', 'https://quicktieproducts.com/', '', 'https://caliberpublicsafety.com/forensic-advantage-redirect/', 'https://www.rivada.com/', 'https://www.americanpan.com/na/', 'https://www.copesan.com/', '', 'https://www.imperva.com/learn/data-security/data-masking/', 'https://readtolead.org/', 'https://suncoastirondoors.com/', 'https://www.terainsights.com/', 'https://www.trybrass.com/', 'https://rokkan.com/', 'https://www.upchannel.com/', 'https://www.lemonaidhealth.com/', 'https://canopyone.com/', 'https://www.fgmarket.com/', 'https://www.gloso.com/', 'https://www.cifinancial.com/ci-gam/ca/en/index.html', 'https://www.altonladders.co.uk/', 'https://swap.mx/', 'https://www.sjearthquakes.com/', 'https://www.susserbank.com/', 'https://hqadvisorypartners.com/', 'https://www.entech.nyc/', 'https://www.cretelligent.com/', 'https://sourcegraphics.com/', 'https://www.tabbyawards.com/', 'https://madbomber.com/', 'https://www.sld.com/', 'https://www.sfcg.org/', 'https://www.fireblocks.com/', 'https://www.geoamps.com/', '', '', 'https://www.floridadental.org/', 'https://www.wealthminder.com/', 'https://www.moxiecorp.com.tw/', 'https://velozient.com/', 'https://secure.seattleopera.org/error/notfound', 'https://roo.vet/', 'https://www.majescoent.com/', 'https://slaytonwireless.com/', 'https://www.things-matrix.com/', 'https://handlethiscup.com/', 'https://www.tampaelectric.com/', '', 'https://www.falkon.ai/', 'https://www.sahomebuilder.com/', 'https://www.wbez.org/', 'http://www.flavorpill.com/', 'https://www.gecinc.com/', 'https://valorpaytech.com/', 'http://javellinsolutions.com/', 'https://www.tridentsales.us/', 'https://www.thuraya.com/', 'https://www.visikard.com/', 'https://www.safeamerica.com/', '', 'http://www.truebalancesolutions.com/', '', 'https://bractlet.com/', 'https://www.webworks.com/', 'https://www.csbitsolutions.com/', 'https://www.flowfold.com/', '', 'https://www.sfaf.org/', 'http://www.aspenta.com/', 'https://www.nextepsystems.com/', 'https://interepinc.com/', 'https://www.tcaregs.com/', 'https://www.printcolor.ch/', 'http://www.ensrmedical.com/', '', 'https://www.tryallset.com/', 'https://trocglobal.com/', 'https://wavebender.net/', '', 'https://entirafamilyclinics.com/', 'https://testsigma.com/', 'http://ww38.reverahealthsystems.com/', '', 'http://www.avitronic.com/', 'https://solvd.cloud/', 'https://www.otak.com/', '', 'http://www.bcfooderp.com/', 'https://korrect.com/', 'https://thinksmartone.com/', 'https://reconnect4health.com/', 'https://tracomedical.com/', '', 'https://medekhealth.com/', '', 'https://www.automationtechnologiesinc.com/', '', 'https://www.cmcserviceexperts.com/', 'https://www.perchenergy.com/', 'https://www.lumen.com/en-us/managed-it-services/sap-ecosystems.html', 'https://cpnpower.com/', 'http://www.grandtextile.com.tw/', 'https://threads.com/', 'https://www.westmarklm.com/', 'http://www.skillrary.com/', 'https://www.massageheights.com/', 'https://www.centralequipment.com/', 'https://www.noodle.com/', 'https://www.eurostop.com/', 'https://www.xpress-systems.com/', '', 'https://hesper.io/', 'https://www.berkeleyrep.org/', 'https://ecp.net/', '', 'https://www.raineyrandall.com/', 'http://rddatasolutions.com/', 'https://www.guidantglobal.com/', 'https://www.mpo.cz/', 'http://www.shdlchem.co.kr/', 'https://boodskap.io/', 'https://www.knighthawkcoal.com/', 'http://www.treeline.co/', 'https://stchealth.com/', 'https://www.parkstonewealth.com/', 'https://mfactory.us/', 'https://ccs.ca/', 'http://www.cutechgroup.com/', 'http://www.koontech.com/', 'https://www.planettelecom.com/', 'https://www.longviewbridge.com/', 'https://www.myglobalfair.com/', 'https://www.complianceonline.com/', 'https://appleassoc.com/', 'http://aeon.co.kr/', 'https://www.mcmtechnology.com/', 'http://globalelectronics.com/', 'https://www.hexagon.co.uk/', 'https://planitmeasuring.com/', 'http://www.beauvaismanor.com/', 'https://www.allegiancetrucks.com/', 'https://xypro.com/', 'https://renegadeinsurance.com/', 'https://www.nexcel.vn/', 'https://exertisenterprise.com/', 'https://www.allsteeloffice.com/', '', 'https://www.ceeva.com/', 'https://beinetworks.com/', '', 'https://www.redboxvoice.com/', 'https://www.hpsmechanical.com/', 'https://www.amdatex.com/', 'https://exa.net.uk/', 'https://www.abaxio.com/', 'https://nikitaclothing.com/', 'https://usnet-1.com/', 'https://www.vilebrequin.com/us/en/home', 'https://reasonfunding.com/', 'https://auditmacs.com/', 'https://www.borlandbenefield.com/', 'https://www.drug-farm.com/', 'http://www.championrenovations.com/', 'https://www.kai-pavement.com/', 'https://www.zj-tuna.com/', 'https://www.maprecruit.ai/', 'https://lssny.org/', 'https://warriorplus.com/', 'http://www.network-control.com', 'https://www.smithcarney.com/', 'https://www.spectranet.com.ng/', 'https://www.coface-usa.com/', '', 'https://www.hausmann.com/', 'https://www.virtualmovingtechnologies.com/', 'https://www.mactac.com/', 'http://hypsports.com/', 'https://synergistix.com/data/', 'https://www.hghcpa.com/', 'https://zenithss.com', 'http://www.contxtcorp.com/', 'http://www.gftuk.com/', 'https://www.rubb.com/', 'https://www.flagshipadvisorypartners.com/', 'https://www.maddockdouglas.com/', 'https://koverai.com/', 'http://www.easytaxi.com/', 'https://bagelbrands.com/', 'https://www.cognitec.com/', 'https://www.konkconsulting.com/EN', 'https://tischlerbise.com/', '', 'https://www.gdpholdings.com/', 'https://wlcac.org/', 'https://www.diligentrobots.com/', '', 'https://www.bootsandmore.net/', 'https://www.protonshub.com/']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Done in 204.8988757133484, 115 broken urls and 0 timeouts with 100 max workers.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import validators\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to check if a URL is valid\n",
    "def is_valid_url(url):\n",
    "    if not url or url != url:\n",
    "        return True\n",
    "    return validators.url(url)\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse url to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    if not parsed_url.scheme:\n",
    "        # Assume http scheme\n",
    "#         corrected_url = f\"http://{parsed_url.netloc}{parsed_url.path}\"\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "        \n",
    "    return corrected_url\n",
    "\n",
    "# Function to get the redirected URL\n",
    "def get_final_redirect_url(url): \n",
    "    try:\n",
    "        # This handles a nonexistent url and 'url != url' handles the NA -> nan case\n",
    "        if not url or url != url:\n",
    "            return ''\n",
    "        \n",
    "        # Sanitize url\n",
    "        corrected_url = sanitize_url(url)\n",
    "        \n",
    "        # Redirects set to true by default\n",
    "#         response = requests.get(corrected_url, allow_redirects = True, stream = True, timeout = 4, headers={\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"})\n",
    "        # DEBUG - requests.head is a slightly shorter call as it doesn't return entire html body of request\n",
    "        response = requests.head(corrected_url, allow_redirects = True, stream = True, timeout = 5, headers={\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"})\n",
    "        final_url = response.url\n",
    "        return final_url\n",
    "    except requests.exceptions.RequestException as re:\n",
    "        # DEBUG\n",
    "#         print(f\"An error occured:{e}\")\n",
    "        return ''\n",
    "    except requests.exception.Timeout as te:\n",
    "        return 'Timeout Exception'\n",
    "\n",
    "# Start script\n",
    "start_time = time.time()\n",
    "max_workers = 0\n",
    "\n",
    "# Load csv\n",
    "file_path = 'Website_Redirects_230919.csv'\n",
    "# low_memory=False to avoid dtype error message \n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "#Ensure source file has 'Websites' column\n",
    "if 'Website' not in df.columns:\n",
    "    print('Original csv file must contain a \\'Website\\' column')\n",
    "else:\n",
    "    # Create ThreadPoolExecutor\n",
    "    max_workers = 100\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Define parallel URL processing function\n",
    "        def process_url(url):\n",
    "            # DEBUG\n",
    "#             print(url)\n",
    "            if is_valid_url(url):\n",
    "                return get_final_redirect_url(url)\n",
    "            else:\n",
    "                return get_final_redirect_url(sanitize_url(url))\n",
    "            \n",
    "        # Use executor to map processing function to URLs\n",
    "#         df['Website Redirect'] = list(executor.map(process_url, df['Website'][:20]))\n",
    "        redirects = list(executor.map(process_url, df['Website'][0:1000]))\n",
    "        # DEBUG\n",
    "        print(redirects)\n",
    "    # Save the modified Dataframe back to the CSV file\n",
    "#     df.to_csv(file_path, index=False)\n",
    "\n",
    "    \n",
    "f'Done in {time.time() - start_time}, {redirects.count(\"\")} broken urls and {redirects.count(\"Timeout Exception\")} timeouts with {max_workers} max workers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73e808fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://everstream.net/', 2.3883795738220215)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time2 = time.time()\n",
    "t_u = 'www.glcom.net'\n",
    "t_u = sanitize_url(t_u)\n",
    "\n",
    "# t_u = requests.head(t_u, allow_redirects=True)\n",
    "t_u = requests.get(t_u, allow_redirects=True)\n",
    "\n",
    "t_u.url, time.time() - time2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db3eed9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-522fbf3b402e>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-522fbf3b402e>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    except (requests.exceptions.RequestException,requests.exceptions.Timeout) as (e1,e2):\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "time3 = time.time()\n",
    "\n",
    "t_u2 = 'www.re-soft.com'\n",
    "t_u2 = sanitize_url(t_u2)\n",
    "\n",
    "try:\n",
    "    t_u2 = requests.get(t_u2, allow_redirects = True, stream = True, timeout = 5, headers={\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"})\n",
    "except (requests.exceptions.RequestException,requests.exceptions.Timeout) as (e1,e2):\n",
    "        # DEBUG\n",
    "#         print(f\"An error occured:{e}\")\n",
    "        print(e1,'\\n',e2)\n",
    "        return ''\n",
    "\n",
    "t_u2.url, time.time() - time3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9379d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Iterate through the URLs in 'Websites' column and capture the final redirected URLs\n",
    "#     for index, row in df.head().iterrows():\n",
    "#     for index, row in df.iloc[:100].iterrows():\n",
    "#     original_url = row['Website']\n",
    "\n",
    "    # Applies get_final_redirect_url to entire 'Website' column\n",
    "    # then creates new column with redirects      \n",
    "#     df['Website Redirects'] = df['Website'][:1000].apply(get_final_redirect_url)\n",
    "#         df['Website Redirects'] = df['Website'].apply(get_final_redirect_url)\n",
    "\n",
    "    # Save the modified Dataframe back to the CSV file\n",
    "#     df.to_csv(file_path, index=False)\n",
    "\n",
    "    # Count for counting errors\n",
    "#     count = 0\n",
    "#     for index, row in df[:301].iterrows():\n",
    "#         original_url = row['Website']\n",
    "#         print(original_url)\n",
    "#         final_url = get_final_redirect_url(original_url)\n",
    "#         if final_url == '':\n",
    "#             count+=1\n",
    "#             continue\n",
    "#         if final_url != original_url+'/':\n",
    "#             print(original_url, '->',final_url)\n",
    "            \n",
    "#         if final_url == original_url:\n",
    "#             print(original_url)\n",
    "\n",
    "# df.head()['Website']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39b83baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['Website'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a952d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParseResult(scheme='', netloc='', path='www.glcom.net', params='', query='', fragment='')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_valid_url('https://sunstonepartners.com/')\n",
    "\n",
    "thisguy = urlparse('www.glcom.net')\n",
    "f\"http://{thisguy.netloc}{thisguy.path}\"\n",
    "# print(thisguy)\n",
    "# thisguy._replace(scheme='http')\n",
    "# print(thisguy)\n",
    "# thisguy.geturl()\n",
    "thisguy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6762113f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.xelapack.com/'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_redirect_url('https://xelapack.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9960c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company ID (18 Char)              0018X00002wGCv0QAG\n",
      "Company Record Type            Sponsor / Lender / IB\n",
      "Company Name                       Sunstone Partners\n",
      "Website                 https://sunstonepartners.com\n",
      "Website Redirects                                NaN\n",
      "Name: 0, dtype: object\n",
      "Company ID (18 Char)                 0018X000037J7rtQAC\n",
      "Company Record Type                            Prospect\n",
      "Company Name                      Applied Learning Labs\n",
      "Website                 https://www.appliedlearning.com\n",
      "Website Redirects                                   NaN\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iloc[:2].iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "779be0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='hawksoftinc.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000236257C2DF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             raise NewConnectionError(\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x00000236257C2DF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m             retries = retries.increment(\n\u001b[0m\u001b[0;32m    756\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='hawksoftinc.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000236257C2DF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7e1d184c76cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# responser = requests.get('http://www.glcom.net', allow_redirects=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# responser = requests.head('http://www.glcom.net', allow_redirects=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresponser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://hawksoftinc.com'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mresponser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# responser\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mhead\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'head'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='hawksoftinc.com', port=443): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x00000236257C2DF0>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# responser = requests.get('http://www.glcom.net', allow_redirects=True)\n",
    "# responser = requests.head('http://www.glcom.net', allow_redirects=True)\n",
    "responser = requests.head('https://hawksoftinc.com', allow_redirects=True)\n",
    "responser.url\n",
    "# responser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f29d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "import urllib.request\n",
    "import colorama,re,queue,threading\n",
    "from colorama import Fore\n",
    "from urllib.parse import *\n",
    "\n",
    "class check_link():\n",
    "    def __init__(self,address):\n",
    "        self.address=address        \n",
    "    def check(self,address):   \n",
    "        try:\n",
    "            req=urllib.request.Request(url=address)\n",
    "            resp=urllib.request.urlopen(req)\n",
    "            if resp.status in [400,404,403,408,409,501,502,503]:\n",
    "                print (Fore.RED+resp.status+\"-\"+resp.reason+\"-->\"+address)          \n",
    "            else: print (Fore.GREEN+\"no problem in-->\"+address)\n",
    "                              \n",
    "        except Exception as e:\n",
    "            print (Fore.YELLOW+\"{}-{}\".format(e,address))\n",
    "            pass   \n",
    "def pattern_adjust(a):  \n",
    "    try:\n",
    "        if re.match('^#' ,a):return 0 \n",
    "        r=urlsplit(a)\n",
    "        if r.scheme=='' and (r.netloc!='' or r.path!=''):\n",
    "            d=urlunsplit(r)\n",
    "            if re.match('^//' ,d):\n",
    "                m= re.search('(?<=//)\\S+', d)\n",
    "                d=m.group(0)  \n",
    "                m=\"https://\"+d\n",
    "                return m\n",
    "        elif r.scheme=='' and r.netloc=='':\n",
    "            return address+a\n",
    "        else:return a\n",
    "    except Exception as e:\n",
    "        pass\n",
    "def extract_link(address):\n",
    "    tags= {'a':'href', 'img':'src', 'script':'src', 'link':'href' }\n",
    "    for key,value in iter(tags.items()):    \n",
    "        try:\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
    "            res=urllib.request.urlopen(urllib.request.Request(url=address, headers=headers))\n",
    "            response=res.read().decode('utf-8') #needs improvement\n",
    "            for link in BeautifulSoup(response,\"html.parser\",parse_only=SoupStrainer(key)): \n",
    "                if link.has_attr(value) and address in link[value]: # address in link[value] to keep testing the target site only\n",
    "                    p=pattern_adjust(link[value])\n",
    "                    if p!=0 and str(p)!='None':        \n",
    "                        newcheck=check_link(p)\n",
    "                        newcheck.check(p)\n",
    "                        if p not in hyperlinks:\n",
    "                            hyperlinks.add(p)\n",
    "                            if website.split('.')[1] in p:#needs improvement\n",
    "                                if not website.endswith(('.png','.jpeg','.js','jpg')):\n",
    "                                    q.put(p)                    \n",
    "        except Exception as e:\n",
    "            print (e,address)                                \n",
    "def threader():\n",
    "    while True:\n",
    "        value=q.get()  \n",
    "        result=extract_link(value)\n",
    "        q.task_done()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    colorama.init()\n",
    "    q=queue.Queue()\n",
    "    global hyperlinks,website\n",
    "    hyperlinks=set()\n",
    "#     website= 'https://www.sozcu.com.tr/' #Target website \n",
    "#     website = 'http://www.hawksoftinc.com'\n",
    "    website = 'http://www.glcom.net'\n",
    "    for x in range(30):\n",
    "        t=threading.Thread(target=threader)\n",
    "        t.deamon=True\n",
    "        t.start()   \n",
    "    q.put(website.strip())\n",
    "    q.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbe8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import validators\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Function to check if a URL is valid\n",
    "def is_valid_url(url):\n",
    "    if not url or url != url:\n",
    "        return True\n",
    "    return validators.url(url)\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse url to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    if not parsed_url.scheme:\n",
    "        # Assume http scheme\n",
    "#         corrected_url = f\"http://{parsed_url.netloc}{parsed_url.path}\"\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "        \n",
    "    return corrected_url\n",
    "\n",
    "# Function to get the redirected URL\n",
    "def get_final_redirect_url(url): \n",
    "    try:\n",
    "        # This handles a nonexistent url and 'url != url' handles the NA -> nan case\n",
    "        if not url or url != url:\n",
    "            return ''\n",
    "        \n",
    "        # Sanitize url\n",
    "        corrected_url = sanitize_url(url)\n",
    "        \n",
    "        # Redirects set to true by default\n",
    "#         response = requests.get(corrected_url, allow_redirects = True, stream = True, timeout = 4, headers={\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"})\n",
    "        # DEBUG - requests.head is a slightly shorter call as it doesn't return entire html body of request\n",
    "        response = requests.head(corrected_url, allow_redirects = True, stream = True, timeout = 5, headers={\"User-Agent\": \"Mozilla/5.0 (X11; CrOS x86_64 12871.102.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.141 Safari/537.36\"})\n",
    "        final_url = response.url\n",
    "        return final_url\n",
    "    except requests.exceptions.RequestException as re:\n",
    "        # DEBUG\n",
    "#         print(f\"An error occured:{e}\")\n",
    "        return ''\n",
    "    except requests.exception.Timeout as te:\n",
    "        return 'Timeout Exception'\n",
    "\n",
    "# Start script\n",
    "start_time = time.time()\n",
    "max_workers = 0\n",
    "\n",
    "# Load csv\n",
    "file_path = 'Website_Redirects_230919.csv'\n",
    "# low_memory=False to avoid dtype error message \n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "#Ensure source file has 'Websites' column\n",
    "if 'Website' not in df.columns:\n",
    "    print('Original csv file must contain a \\'Website\\' column')\n",
    "else:\n",
    "    # Create ThreadPoolExecutor\n",
    "    max_workers = 100\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Define parallel URL processing function\n",
    "        def process_url(url):\n",
    "            # DEBUG\n",
    "#             print(url)\n",
    "            if is_valid_url(url):\n",
    "                return get_final_redirect_url(url)\n",
    "            else:\n",
    "                return get_final_redirect_url(sanitize_url(url))\n",
    "            \n",
    "        # Use executor to map processing function to URLs\n",
    "#         df['Website Redirect'] = list(executor.map(process_url, df['Website'][:20]))\n",
    "        redirects = list(executor.map(process_url, df['Website'][0:1000]))\n",
    "        # DEBUG\n",
    "        print(redirects)\n",
    "    # Save the modified Dataframe back to the CSV file\n",
    "#     df.to_csv(file_path, index=False)\n",
    "\n",
    "    \n",
    "f'Done in {time.time() - start_time}, {redirects.count(\"\")} broken urls and {redirects.count(\"Timeout Exception\")} timeouts with {max_workers} max workers.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20e4f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing ['https://sunstonepartners.com/', 'https://www.appliedlearning.com/', 'https://www.forsalebyowner.com/', 'http://comsatmedia-en.tumblr.com/', 'https://www.kdanmobile.com/', 'https://www.sunchlorellausa.com', 'https://www.papemh.com', 'https://everstream.net/', 'https://wackerbrewing.com/', 'https://21stsoft.com', 'https://marketingbysos.com', 'https://www.wittmann-group.com/en', 'https://www.xelapack.com/', 'https://epicio.com', 'https://mammachia.com', 'https://cambli.com', 'http://hawksoftinc.com', 'https://www.river-run.com', 'https://www.re-soft.com/', 'https://www.pavestone.com', 'https://www.framedisplays.com', 'https://www.virtually-anywhere.com', 'https://abak.hopem.com', 'https://www.jswsteel.us', 'https://www.glr.qc.ca', 'http://www.woodrock.com', 'https://tracegenomics.com', 'https://avada.com', 'https://contactind.com', 'https://www.cthedge.org', 'http://greenecowalls.com', 'https://www.ripoffreportremovalhelp.com', 'https://www.kumi-na.com', 'https://www.cwnetworks.com', 'https://www.ptechnosoft.com', 'https://www.agmimports.com', 'https://longevity.inc', 'https://www.ramboard.com', 'https://www.macuhealth.com', 'https://forahealthyme.com', 'https://cloudsilicon.com', 'https://www.unitedpacificpallet.com', 'https://breakthroughenergy.org', 'https://www.traceinternational.org', 'https://www.renocavanaugh.com', 'https://blankfactor.com', 'https://www.pinta-elements.com', 'http://www.covalentmediasystems.com', 'https://www.kelmscott.com', 'https://transcendinfra.com', 'https://edgewood.org', 'https://traivefinance.com', 'https://www.bizx.com', 'https://ecmins.com', 'https://www.enveloprisk.com', 'http://sensormedtech.com', 'https://www.newgroupmedia.com', 'https://www.nelsonsystems.com', 'https://www.adsrole.com', 'https://www.usef.org', 'https://acadia.io', 'https://www.endosoft.com', 'https://www.pro-tow.com', 'https://pexapark.com', 'https://www.yf-metal.com', 'https://www.web.asignio.com', 'https://www.printgiant.com', 'https://www.ease.co', 'https://www.ussfcu.org', 'https://www.sporter.com', 'http://www.imagineeasy.com', 'https://www.paramountexport.net', 'https://brightstar.net', 'http://www.finelight.com', 'http://www.bladefinancialservices.com', 'https://www.hwtrek.com', 'https://www.viewgol.com', 'https://lamontanita.coop', 'https://www.pathenviro.com', 'https://www.affinityventures.com', 'http://www.medtech-grp.com', 'https://verityplatform.com', 'https://restorepoint.ai', 'https://stonehillstrategiccapital.com', 'https://www.procaretherapy.com', 'https://www.aseg.com', 'https://www.leachgarner.com', 'https://www.duvora.com', 'https://www.altiusva.com', 'https://coxpools.com', 'http://invaterra.com', 'http://www.gnuralnet.com', 'https://pfnyc.org', 'http://www.e-acen.com', 'https://precisionopinion.com', 'http://www.approgence.com', 'https://custommicrowave.com', 'http://www.tracewise.com', 'https://bonniekatzdesign.com', 'https://www.dentalrevenue.com']\n",
      "Client error for url: https://www.framedisplays.com, Cannot connect to host www.framedisplays.com:443 ssl:default [getaddrinfo failed]\n",
      "Client error for url: https://forahealthyme.com, Cannot connect to host forahealthyme.com:443 ssl:True [SSLCertVerificationError: (1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'forahealthyme.com'. (_ssl.c:1125)\")]\n",
      "Timed out for url: http://hawksoftinc.com, \n",
      "Client error for url: https://www.yf-metal.com, Cannot connect to host www.yf-metal.com:443 ssl:True [SSLCertVerificationError: (1, \"[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: Hostname mismatch, certificate is not valid for 'www.yf-metal.com'. (_ssl.c:1125)\")]\n",
      "Client error for url: http://www.imagineeasy.com, Cannot connect to host www.imagineeasy.com:80 ssl:default [getaddrinfo failed]\n",
      "Timed out for url: https://contactind.com, \n",
      "Client error for url: http://www.finelight.com, Cannot connect to host www.finelight.com:80 ssl:default [getaddrinfo failed]\n",
      "Client error for url: https://brightstar.net, Cannot connect to host brightstar.net:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1125)')]\n",
      "Client error for url: http://www.medtech-grp.com, Cannot connect to host www.medtech-grp.com:80 ssl:default [getaddrinfo failed]\n",
      "Client error for url: https://www.aseg.com, Cannot connect to host www.aseg.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1125)')]\n",
      "Client error for url: https://www.duvora.com, Cannot connect to host duvora.com:443 ssl:default [getaddrinfo failed]\n",
      "Client error for url: http://www.tracewise.com, Cannot connect to host www.tracewise.com:443 ssl:True [SSLCertVerificationError: (1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1125)')]\n",
      "['https://sunstonepartners.com/', 'https://www.appliedlearning.com/', 'https://www.forsalebyowner.com/', 'http://comsatmedia-en.tumblr.com/', 'https://www.kdanmobile.com/', 'https://www.sunchlorellausa.com', 'https://www.papemh.com', 'https://everstream.net/', 'https://wackerbrewing.com/', 'https://21stsoft.com', 'https://marketingbysos.com', 'https://www.wittmann-group.com/en', 'https://www.xelapack.com/', 'https://epicio.com', 'https://mammachia.com', 'https://cambli.com', 'Timeout Error', 'https://www.river-run.com', 'https://www.re-soft.com/', 'https://www.pavestone.com', 'Client Error', 'https://www.virtually-anywhere.com', 'https://abak.hopem.com', 'https://jswsteel.us/', 'https://www.glr.qc.ca', 'http://www.woodrock.com', 'https://tracegenomics.com', 'https://avada.com', 'Timeout Error', 'https://www.cthedge.org', 'https://greenecowalls.com/', 'https://www.ripoffreportremovalhelp.com', 'https://www.kumi-na.com', 'https://libertynetworks.com/', 'https://www.ptechnosoft.com', 'https://agmimports.com/', 'https://longevity.inc', 'https://www.ramboard.com', 'https://www.macuhealth.com', 'Client Error', 'http://officemdr.com', 'https://www.unitedpacificpallet.com', 'https://breakthroughenergy.org', 'https://www.traceinternational.org', 'https://www.renocavanaugh.com', 'https://blankfactor.com', 'https://www.pinta-elements.com', 'http://www.covalentmediasystems.com', 'https://mittera.com/higher-education/', 'https://transcendinfra.com', 'https://edgewood.org', 'https://traivefinance.com', 'https://www.bizx.com', 'https://ecmins.com', 'https://www.enveloprisk.com', 'http://sensormedtech.com', 'https://www.newgroupmedia.com/home/', 'https://www.nelsonsystems.com', 'https://www.adsrole.com', 'https://www.usef.org/errors/not-found?aspxerrorpath=/', 'https://acadia.io', 'https://www.endosoft.com', 'https://www.pro-tow.com', 'https://pexapark.com', 'Client Error', 'https://www.web.asignio.com', 'https://www.printgiant.com', 'https://www.ease.co', 'https://www.ussfcu.org', 'https://www.sporter.com/en-ae/', 'Client Error', 'https://www.paramountexport.net', 'Client Error', 'Client Error', 'https://www.bladefinancialservices.com/', 'https://www.hwtrek.com', 'https://www.viewgol.com', 'https://lamontanita.coop', 'https://www.pathenviro.com', 'https://www.affinityventures.com', 'Client Error', 'https://verityplatform.com', 'https://restorepoint.ai', 'https://www.peachtreegroup.com/', 'https://www.procaretherapy.com', 'Client Error', 'https://www.leachgarner.com', 'Client Error', 'https://www.altiusva.com', 'https://coxpools.com', 'http://invaterra.com', 'https://www.gnuralnet.com/', 'https://pfnyc.org', 'http://www.e-acen.com', 'https://precisionopinion.com', 'http://www.approgence.com', 'https://custommicrowave.com', 'Client Error', 'https://bonniekatzdesign.com', 'https://www.dentalrevenue.com']\n",
      "Redirects have been added to the CSV file.\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import validators\n",
    "\n",
    "# Note: cannot have excel sheet open while doing this for permission.\n",
    "# TOOD: (1) do with semaphores instead of threads (?)\n",
    "        #(2) research why this is better\n",
    "        #(3) install and use aiodns\n",
    "        #(4) cache bad urls in excel column\n",
    "\n",
    "nest_asyncio.apply()\n",
    "MAX_CONCURRENT_REQUESTS = 10\n",
    "\n",
    "async def check_url(session, url, semaphore):\n",
    "    # DEBUG\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            async with session.head(url, allow_redirects=True, timeout=10) as response:\n",
    "                return str(response.url) # Return final URL as string\n",
    "        except asyncio.TimeoutError as te:\n",
    "            print(f\"Timed out for url: {url}, {te}\")\n",
    "            return 'Timeout Error'\n",
    "        except aiohttp.ClientError as ce:\n",
    "            print(f\"Client error for url: {url}, {ce}\")\n",
    "            return 'Client Error'\n",
    "\n",
    "async def process_urls(urls):\n",
    "    print('processing',urls)\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [check_url(session, url, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "        \n",
    "        # Process responses\n",
    "#         for final_url in results:\n",
    "#             if final_url:\n",
    "#                 print(f\"URL: {final_url}\")\n",
    "#             else:\n",
    "#                 print(\"Request failed or timed out\")\n",
    "                \n",
    "def initial_processing(url):\n",
    "    if not url or url != url or pd.isna(url):\n",
    "            return ''\n",
    "        \n",
    "    # Sanitize url -> TODO change name so not same as in sanitize?\n",
    "    corrected_url = sanitize_url(url)\n",
    "    return corrected_url\n",
    "\n",
    "def update_redirect_urls(file_path, urls, redirect_urls):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    print(redirect_urls)\n",
    "    df['Website Redirect'][:100] = redirect_urls\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "# Function to check if a URL is valid\n",
    "async def is_valid_url(url):\n",
    "    if not url or url != url:\n",
    "        return True\n",
    "    return validators.url(url)\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse url to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    if not parsed_url.scheme:\n",
    "        # Assume http scheme\n",
    "#         corrected_url = f\"http://{parsed_url.netloc}{parsed_url.path}\"\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "        \n",
    "    return corrected_url\n",
    "\n",
    "file_path = 'Website_Redirects_230919.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "if 'Website' not in df.columns:\n",
    "    print(\"The CSV file must have a 'Websites' column containing the URLs.\")\n",
    "else:\n",
    "    raw_urls = df['Website'][:100].tolist()\n",
    "    redirect_urls = df.get('Website Redirect', pd.Series(dtype=str)).tolist()\n",
    "    \n",
    "    # Check if 'Website Redirect' column is already populated\n",
    "    for i, redirect_url in enumerate(redirect_urls):\n",
    "        if redirect_url and validators.url(redirect_url):\n",
    "            raw_urls[i] = redirect_url\n",
    "#         elif redirect_url == 'Timeout Error'\n",
    "            \n",
    "    # Process the URLs asynchronously\n",
    "    sanitized_urls = [initial_processing(url) for url in raw_urls]\n",
    "    valid_urls = [url for url in sanitized_urls if validators.url(url)]\n",
    "\n",
    "    # Run the asynchronous function using asyncio.run()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    final_urls = loop.run_until_complete(process_urls(valid_urls))\n",
    "\n",
    "    # Update 'Website Redirect' column in the CSV file with final URLs\n",
    "    update_redirect_urls(file_path, valid_urls, final_urls)\n",
    "    \n",
    "    # Sanitize URLs and remove NaN values\n",
    "#     sanitized_urls = [initial_processing(url) for url in raw_urls]\n",
    "#     # DEBUG\n",
    "# #     sanitized_urls = raw_urls.apply(sanitize_url)\n",
    "#     valid_urls = [url for url in sanitized_urls if validators.url(url)]\n",
    "    \n",
    "#     # Check if an event loop is already running\n",
    "#     if asyncio.get_event_loop().is_running():\n",
    "#         loop = asyncio.get_event_loop()\n",
    "#     else:\n",
    "#         loop = asyncio.new_event_loop()\n",
    "#         asyncio.set_event_loop(loop)\n",
    "\n",
    "#     # Asynchronously check URLs\n",
    "#     loop = asyncio.get_event_loop()\n",
    "#     print('jere')\n",
    "#     results = loop.run_until_complete(process_urls(valid_urls))\n",
    "#     print('results', results)\n",
    "\n",
    "#     # Update DataFrame with results\n",
    "#     df['Website Redirect'] = results\n",
    "\n",
    "    # Save the modified DataFrame back to the CSV file\n",
    "#     df.to_csv(file_path, index=False)\n",
    "    print(\"Redirects have been added to the CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd1cc8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://sunstonepartners.com/', 'https://www.appliedlearning.com/', 'https://www.forsalebyowner.com/', 'http://comsatmedia-en.tumblr.com/', 'https://www.kdanmobile.com/', 'https://www.sunchlorellausa.com', 'https://www.papemh.com', 'http://www.glcom.net', 'http://wackerbrewing.com', 'https://21stsoft.com', 'https://marketingbysos.com', 'https://www.wittmann-group.com', 'https://xelapack.com', 'https://epicio.com', 'https://mammachia.com', 'https://cambli.com', 'http://hawksoftinc.com', 'https://www.river-run.com', 'http://www.re-soft.com', 'https://www.pavestone.com']\n"
     ]
    }
   ],
   "source": [
    "# without semaphore\n",
    "\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import validators\n",
    "\n",
    "# TODO: Add no response and last fail/run through only fails\n",
    "\n",
    "async def check_url(session, url):\n",
    "# async def check_url(session, url, semaphore):\n",
    "    # DEBUG\n",
    "#     async with semaphore:\n",
    "        try:\n",
    "            async with session.head(url, allow_redirects=True, timeout=10) as response:\n",
    "                return str(response.url) # Return final URL as string\n",
    "        except asyncio.TimeoutError as te:\n",
    "            print(f\"Timed out for url: {url}, {te}\")\n",
    "            return None\n",
    "        except aiohttp.ClientError as ce:\n",
    "            print(f\"Client error for url: {url}, {ce}\")\n",
    "            return None\n",
    "\n",
    "async def process_urls(urls):\n",
    "# async def process_urls2(urls):\n",
    "    print('processing',urls)\n",
    "#     semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "#     async with aiohttp.ClientSession() as session:\n",
    "#         tasks = [check_url(session, url, semaphore) for url in urls]\n",
    "#         results = await asyncio.gather(*tasks)\n",
    "#         return results\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [check_url(session, url) for url in urls]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "def initial_processing(url):\n",
    "    if not url or url != url or pd.isna(url):\n",
    "            return ''\n",
    "        \n",
    "    # Sanitize url -> TODO change name so not same as in sanitize?\n",
    "    corrected_url = sanitize_url(url)\n",
    "    return corrected_url\n",
    "\n",
    "def update_redirect_urls(file_path, urls, redirect_urls):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    print(redirect_urls)\n",
    "#     df['Website Redirect'] = redirect_urls\n",
    "#     df.to_csv(file_path, index=False)\n",
    "\n",
    "# Function to check if a URL is valid\n",
    "async def is_valid_url(url):\n",
    "    if not url or url != url:\n",
    "        return True\n",
    "    return validators.url(url)\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse url to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    if not parsed_url.scheme:\n",
    "        # Assume http scheme\n",
    "#         corrected_url = f\"http://{parsed_url.netloc}{parsed_url.path}\"\n",
    "        sanitized_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        sanitized_url = parsed_url.geturl()\n",
    "        \n",
    "    return sanitized_url\n",
    "\n",
    "file_path = 'Website_Redirects_230919.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "if 'Website' not in df.columns:\n",
    "    print(\"The CSV file must have a 'Websites' column containing the URLs.\")\n",
    "else:\n",
    "    raw_urls = df['Website'][:20].tolist()\n",
    "    redirect_urls = df['Website Redirect'][:20].tolist()\n",
    "    input_urls = []\n",
    "    \n",
    "    # Check if 'Website Redirect' column is already populated\n",
    "    for i, redirect_url in enumerate(redirect_urls):\n",
    "        if redirect_url and validators.url(redirect_url):\n",
    "            input_urls.append(redirect_url)\n",
    "        else:\n",
    "            input_urls.append(raw_urls[i])\n",
    "            \n",
    "    # Process the URLs asynchronously\n",
    "    sanitized_urls = [initial_processing(url) for url in input_urls]\n",
    "    valid_urls = [url for url in sanitized_urls if validators.url(url)]\n",
    "    \n",
    "    print(valid_urls)\n",
    "    \n",
    "    final_urls = process_urls(valid_urls)\n",
    "# final_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c56c600d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x000001CF32ACE0A0>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.glcom.net\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tasks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-facca9e8538d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tasks' is not defined"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "\n",
    "url = 'http://www.glcom.net'\n",
    "\n",
    "session = aiohttp.ClientSession()\n",
    "async with session.head(url, timeout=10) as ans:\n",
    "    print(ans.url)\n",
    "\n",
    "await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39f4c25",
   "metadata": {},
   "source": [
    "## Sent script\n",
    "With comments/TODOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec17458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import validators\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# TODO\n",
    "  # (1) Increase MAX_CONCURRENT_REQUESTS\n",
    "  # (2) Figure out way to scan in one click.\n",
    "    # (a) Don't test already redirected values?\n",
    "    # (b) Go through all one time, see if works.\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "nest_asyncio.apply()\n",
    "MAX_CONCURRENT_REQUESTS = 10\n",
    "# Slice for all websites: slice(0,300000)\n",
    "index_range = slice(0,500)\n",
    "\n",
    "def initial_processing(url):\n",
    "    if not url or url != url or pd.isna(url):\n",
    "        return ''\n",
    "    \n",
    "    # Sanitize URL\n",
    "    corrected_url = sanitize_url(url)\n",
    "    return corrected_url\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse URL to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    if not parsed_url.scheme:\n",
    "    # Assume http scheme\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "\n",
    "    return corrected_url\n",
    "\n",
    "# DEBUG\n",
    "# async def check_url(session, url, semaphore, i):\n",
    "async def check_url(session, url, semaphore):\n",
    "  # DEBUG\n",
    "  # if i % 10:\n",
    "    # clear_output()\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            async with session.head(url, allow_redirects=True, timeout=10) as response:\n",
    "                return str(response.url) # Return final URL as string\n",
    "        # Catch errors\n",
    "        except asyncio.TimeoutError as te:\n",
    "          # print(f\"Timed out for url: {url}, {te}\")\n",
    "          return 'Timeout Error'\n",
    "        except aiohttp.ClientError as ce:\n",
    "          # print(f\"Client error for url: {url}, {ce}\")\n",
    "          return 'Client Error'\n",
    "        except ValueError as ve:\n",
    "          # print(f\"Value error for url: {url}, {ve}\")\n",
    "          return 'Value Error'\n",
    "\n",
    "async def process_urls(urls):\n",
    "    print(f\"processing {len(urls)} urls\")\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        # tasks = [check_url(session, url, semaphore, i) for i, url in enumerate(urls)]\n",
    "        tasks = [check_url(session, url, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "\n",
    "def update_redirect_urls(file_path, urls, redirect_urls):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    # print(redirect_urls)\n",
    "    df['Website Redirect'][index_range] = redirect_urls\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path = './Website_Redirects_230919.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "if 'Website' not in df.columns:\n",
    "    print(\"The CSV file must have a 'Website' column containing the URLs.\")\n",
    "else:\n",
    "    raw_urls = df['Website'][index_range].tolist()\n",
    "    redirect_urls = df.get('Website Redirect', pd.Series(dtype=str)).tolist()[index_range]\n",
    "\n",
    "    # Check if 'Website Redirect' column is already populated (with valid URL)\n",
    "    for i, redirect_url in enumerate(redirect_urls):\n",
    "        if redirect_url and validators.url(redirect_url):\n",
    "            raw_urls[i] = redirect_url\n",
    "\n",
    "    # Process the URLs asynchronously\n",
    "    sanitized_urls = [initial_processing(url) for url in raw_urls]\n",
    "    valid_urls = [url if validators.url(url) else '' for url in sanitized_urls]\n",
    "\n",
    "    # Run the asynchronous function using asyncio.run()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    final_urls = loop.run_until_complete(process_urls(valid_urls))\n",
    "\n",
    "    # Update 'Website Redirect' column in the CSV file with final URLs\n",
    "    update_redirect_urls(file_path, valid_urls, final_urls)\n",
    "\n",
    "    print(f\"'Website Redirect' column updated in {time.time()-start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06b416",
   "metadata": {},
   "source": [
    "## Report\n",
    "\n",
    "### Threads Times\n",
    "\n",
    "#### Threads | URLs | Time (seconds)\n",
    "10  | 100    | 16\\\n",
    "10  | 3000   | 813\\\n",
    "10  | 10000  | 134\\\n",
    "10  | 100000 | 39,000 (11 hours)\\\n",
    "10  | 250000 | 107,000 (29 hours)\\\n",
    "100 | 3000   | 326\\\n",
    "500 | 3000   | 68"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
