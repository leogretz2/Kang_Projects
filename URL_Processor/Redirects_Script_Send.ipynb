{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22e70e5",
   "metadata": {},
   "source": [
    "# Redirect Script\n",
    "Run the cell below this one\\\n",
    "Change the **index_range = slice(0,300000)** line for more precise ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a28f8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw 16\n",
      "processing 16 urls\n",
      "re ['Client Error', 'https://www.river-run.com', 'https://www.re-soft.com/', 'https://www.pavestone.com', 'https://www.framedisplays.com', 'https://www.virtually-anywhere.com', 'https://abak.hopem.com', 'https://jswsteel.us/', 'https://www.glr.qc.ca', 'http://www.woodrock.com', 'https://tracegenomics.com', 'https://avada.com', 'Client Error', 'https://www.cthedge.org', 'https://greenecowalls.com/', 'https://www.ripoffreportremovalhelp.com']\n",
      "'Website Redirect' column updated with 16 new urls in 63.296077728271484 seconds.\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import validators\n",
    "import time\n",
    "    \n",
    "nest_asyncio.apply()\n",
    "\n",
    "def initial_processing(url):\n",
    "    if not url or url != url or pd.isna(url):\n",
    "        return ''\n",
    "    \n",
    "    # Sanitize URL\n",
    "    corrected_url = sanitize_url(url)\n",
    "    return corrected_url\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse URL to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    if not parsed_url.scheme:\n",
    "    # Assume http scheme\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "\n",
    "    return corrected_url\n",
    "\n",
    "async def check_url(session, url, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            async with session.head(url, allow_redirects=True, timeout=100) as response:\n",
    "                return str(response.url) # Return final URL as string\n",
    "        # Catch errors\n",
    "        except asyncio.TimeoutError as te:\n",
    "            return 'Timeout Error'\n",
    "        except aiohttp.ClientError as ce:\n",
    "            return 'Client Error'\n",
    "        except ValueError as ve:\n",
    "            return 'Value Error'\n",
    "\n",
    "async def process_urls(urls, MAX_CONCURRENT_REQUESTS):\n",
    "    print(f\"processing {len(urls)} urls\")\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [check_url(session, url, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        print('re',results)\n",
    "        return results\n",
    "\n",
    "def update_redirect_urls(file_path, index_range, redirect_urls):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    df_col = df['Website Redirect'] if 'Website Redirect' in df else ['']*len(df)\n",
    "    new_list = list(df_col[:index_range.start]) + redirect_urls + list(df_col[index_range.stop:])\n",
    "    df['Website Redirect'] = new_list\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    MAX_CONCURRENT_REQUESTS = 1000\n",
    "\n",
    "    file_path = './Excel_Sheets_Public/Website_Redirects_230919.csv'\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Change this line for more precise ranges\n",
    "    index_range = slice(16,32)\n",
    "\n",
    "    if 'Website' not in df.columns:\n",
    "        print(\"The CSV file must have a 'Website' column containing the URLs.\")\n",
    "    else:\n",
    "        raw_urls, redirect_urls = df['Website'][index_range].tolist(), []\n",
    "        if 'Website Redirect' in df:\n",
    "            redirect_urls = df.get('Website Redirect', pd.Series(dtype=str)).tolist()[index_range]\n",
    "\n",
    "        # Check if 'Website Redirect' column is already populated (with valid URL)\n",
    "        for i, redirect_url in enumerate(redirect_urls):\n",
    "            if redirect_url and validators.url(redirect_url):\n",
    "                raw_urls[i] = redirect_url\n",
    "\n",
    "        print('raw',len(raw_urls))\n",
    "        # Process the URLs asynchronously\n",
    "        sanitized_urls = [initial_processing(url) for url in raw_urls]\n",
    "        valid_urls = [url if validators.url(url) else '' for url in sanitized_urls]\n",
    "\n",
    "\n",
    "        # Run the asynchronous function using asyncio.run()\n",
    "        loop = asyncio.get_event_loop()\n",
    "        final_urls = loop.run_until_complete(process_urls(valid_urls, MAX_CONCURRENT_REQUESTS))\n",
    "\n",
    "        # Update 'Website Redirect' column in the CSV file with final URLs\n",
    "        update_redirect_urls(file_path, index_range, final_urls)\n",
    "\n",
    "        print(f\"'Website Redirect' column updated with {len(final_urls)} new urls in {time.time()-start_time} seconds.\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d183629f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300090909090909"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = './Excel_Sheets/Website_Redirects_230919.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "errno, count = 0,0\n",
    "for rd in list(df['Website Redirect']):\n",
    "    # if type(rd) == str and 'Timeout Error' in rd:\n",
    "    if type(rd) == str:\n",
    "        if 'Error' in rd:\n",
    "            errno+=1\n",
    "        count +=1 \n",
    "\n",
    "errno/count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
