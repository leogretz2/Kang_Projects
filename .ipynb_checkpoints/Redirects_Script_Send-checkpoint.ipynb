{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab5ba651",
   "metadata": {},
   "source": [
    "# Redirect Script\n",
    "Run the cell below this one\\\n",
    "Change the **index_range = slice(0,300000)** line for more precise ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b304232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 500 urls\n",
      "'Website Redirect' column updated in 146.62903261184692 seconds.\n"
     ]
    }
   ],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "import validators\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "    \n",
    "nest_asyncio.apply()\n",
    "MAX_CONCURRENT_REQUESTS = 10\n",
    "# Change this line for more precise ranges\n",
    "index_range = slice(0,300000)\n",
    "\n",
    "def initial_processing(url):\n",
    "    if not url or url != url or pd.isna(url):\n",
    "        return ''\n",
    "    \n",
    "    # Sanitize URL\n",
    "    corrected_url = sanitize_url(url)\n",
    "    return corrected_url\n",
    "\n",
    "# Function to sanitize/correct URLs missing pieces\n",
    "def sanitize_url(url):\n",
    "    # Parse URL to correct any issues then reconstruct\n",
    "    parsed_url = urlparse(url)\n",
    "\n",
    "    if not parsed_url.scheme:\n",
    "    # Assume http scheme\n",
    "        corrected_url = 'http://'+parsed_url.netloc + parsed_url.path + parsed_url.params + parsed_url.query + parsed_url.fragment\n",
    "    else:\n",
    "        corrected_url = parsed_url.geturl()\n",
    "\n",
    "    return corrected_url\n",
    "\n",
    "async def check_url(session, url, semaphore):\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            async with session.head(url, allow_redirects=True, timeout=10) as response:\n",
    "                return str(response.url) # Return final URL as string\n",
    "        # Catch errors\n",
    "        except asyncio.TimeoutError as te:\n",
    "            return 'Timeout Error'\n",
    "        except aiohttp.ClientError as ce:\n",
    "            return 'Client Error'\n",
    "        except ValueError as ve:\n",
    "            return 'Value Error'\n",
    "\n",
    "async def process_urls(urls):\n",
    "    print(f\"processing {len(urls)} urls\")\n",
    "    semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [check_url(session, url, semaphore) for url in urls]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n",
    "\n",
    "def update_redirect_urls(file_path, urls, redirect_urls):\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    df['Website Redirect'][index_range] = redirect_urls\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path = './Website_Redirects_230919.csv'\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "if 'Website' not in df.columns:\n",
    "    print(\"The CSV file must have a 'Website' column containing the URLs.\")\n",
    "else:\n",
    "    raw_urls = df['Website'][index_range].tolist()\n",
    "    redirect_urls = df.get('Website Redirect', pd.Series(dtype=str)).tolist()[index_range]\n",
    "\n",
    "    # Check if 'Website Redirect' column is already populated (with valid URL)\n",
    "    for i, redirect_url in enumerate(redirect_urls):\n",
    "        if redirect_url and validators.url(redirect_url):\n",
    "            raw_urls[i] = redirect_url\n",
    "\n",
    "    # Process the URLs asynchronously\n",
    "    sanitized_urls = [initial_processing(url) for url in raw_urls]\n",
    "    valid_urls = [url if validators.url(url) else '' for url in sanitized_urls]\n",
    "\n",
    "    # Run the asynchronous function using asyncio.run()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    final_urls = loop.run_until_complete(process_urls(valid_urls))\n",
    "\n",
    "    # Update 'Website Redirect' column in the CSV file with final URLs\n",
    "    update_redirect_urls(file_path, valid_urls, final_urls)\n",
    "\n",
    "    print(f\"'Website Redirect' column updated in {time.time()-start_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
